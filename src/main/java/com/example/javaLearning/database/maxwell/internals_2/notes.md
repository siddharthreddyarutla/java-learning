# ğŸ§  STEP 2 â€” How Maxwell Works Internally (Deep but Clear)

Weâ€™ll answer **three interview-critical questions**:

1ï¸âƒ£ Where does Maxwell read data from?
2ï¸âƒ£ How does it know *what* changed?
3ï¸âƒ£ How does it resume safely after failures?

---

## 2.1 Where Maxwell Reads From (Key Insight)

Maxwell **does NOT read tables**.

It reads **MySQL Binary Logs (binlogs)**.

### Think of binlog as:

* Append-only change log
* Written by MySQL itself
* Used for replication & recovery

```
INSERT / UPDATE / DELETE
        â†“
     Binlog
        â†“
   Maxwell
```

ğŸ“Œ Interview line:

> *â€œMaxwell listens to the same replication stream that MySQL replicas use.â€*

That sentence alone shows deep understanding.

---

## 2.2 How Maxwell Connects to MySQL

Maxwell connects as a **replication client**.

It needs:

* `REPLICATION SLAVE`
* `REPLICATION CLIENT`

Thatâ€™s why:

* It can read binlogs
* It tracks binlog filename + offset

ğŸ“Œ Important:

> Maxwell can connect to **master or replica** (replica is recommended in prod).

---

## 2.3 Binlog Formats (VERY IMPORTANT)

MySQL supports:

1. STATEMENT
2. ROW
3. MIXED

### Why Maxwell **requires ROW**

#### STATEMENT-based âŒ

```sql
UPDATE users SET salary = salary * 1.1 WHERE dept = 'ENG';
```

Problems:

* Which rows changed?
* Old values?
* Non-deterministic

#### ROW-based âœ…

MySQL writes:

```
Row ID 10: salary 100 â†’ 110
Row ID 11: salary 120 â†’ 132
```

ğŸ“Œ Interview killer line:

> *â€œROW-based binlogs capture the effect of a change, not the SQL that caused it.â€*

Thatâ€™s why CDC tools **require ROW format**.

---

## 2.4 What Maxwell Extracts from Binlog

From each row event, Maxwell gets:

* Database name
* Table name
* Primary key
* Column values
* Old values (for updates)
* Event type (insert/update/delete)
* Timestamp

Then it converts this into **JSON events**.

---

## 2.5 Internal Flow (Memorize This)

```
MySQL
  â†“ (writes)
Binlog (ROW events)
  â†“
Maxwell Replication Client
  â†“
Event Parser
  â†“
JSON Serializer
  â†“
Kafka Producer
```

ğŸ“Œ Interviewers LOVE when you explain flow clearly.

---

## 2.6 How Maxwell Tracks Progress (Offsets)

This is huge for failure questions.

Maxwell tracks:

* Binlog file name
* Binlog position (offset)

It stores this in:

* Its own MySQL schema (`maxwell.positions`)
* (optionally) Kafka

### On restart:

* Reads last saved position
* Resumes from **exact same event**

ğŸ“Œ Interview-ready answer:

> *â€œMaxwell is fault-tolerant because it persists binlog offsets independently of Kafka.â€*

---

## 2.7 What About Transactions?

Important nuance.

* Binlog events are written **after transaction commit**
* Maxwell only sees **committed data**
* No dirty reads

However:

* Maxwell emits **row-level events**
* Transaction boundaries are not explicit

ğŸ“Œ Say this carefully:

> *â€œMaxwell preserves data correctness but not transactional grouping.â€*

---

## 2.8 Ordering Guarantees

* Binlog is **strictly ordered**
* Maxwell preserves binlog order
* Ordering is per:

    * Single MySQL instance
    * Single partition if keyed correctly

ğŸ“Œ Interview tip:

> Ordering across tables is preserved as written in binlog.

---

## Common Interview Traps (Now You Can Handle Them)

**Q: Does Maxwell miss fast updates?**
âŒ No â€” binlog captures everything

**Q: Is there DB load?**
âœ… Minimal â€” binlog already exists

**Q: Can Maxwell rewind?**
âš  Only if binlog still exists

---

## One-line Summary (Lock This In)

> **â€œMaxwell works by acting as a MySQL replication client, parsing ROW-based binlogs into ordered JSON change events and publishing them to Kafka.â€**

If you say this confidently, interviewer knows youâ€™re solid.